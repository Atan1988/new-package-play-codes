return(F_NQs)
}
get_nth <- function(x, n) x[[n]]
system.time(F1Q <- Forward_NQ(ini_df = claims_ini, eval_quarter = starting_quarter,
df_quarter_col = "CurTransDate", N= 100))
cum_dfs <- bind_rows(lapply(F1Q, get_nth, n = 1)) %>%
filter(RptDate < TransDate)
alltrans <- bind_rows(lapply(F1Q, get_nth, n = 2))
###we cut off the claim values at 2017-6-30
cum_dfs_cutoff <- cum_dfs %>% filter(TransDate <= as.Date("2017-06-30")) %>%
arrange(AccDate, ClaimID, TransDate) %>%
select(ClaimID, AccDate, Segment, RptDate, ClsDate, TransDate, Ini_Inc)
cum_dfs_cutoff <- cum_dfs_cutoff %>%
group_by(ClaimID ) %>%
mutate(Lag_Ini_Inc = lag(Ini_Inc)) %>%
mutate(Q = ceiling((as.numeric(month(AccDate)) - 0.01)/3) ) %>%
left_join(quarter_ends) %>%
mutate(GrpAccDate = as.Date(paste0(year(AccDate), "-", end_date)))%>%
mutate(Age = (year(TransDate) - year(GrpAccDate)) * 12 +
month(TransDate) - month(GrpAccDate) + 3)%>%
mutate(LinkRatio = Ini_Inc / Lag_Ini_Inc)
cum_dfs_cutoff %>% ungroup %>%
filter(is.na(ClsDate) | ClsDate == TransDate) %>%
filter(Age %% 6 == 0 | Age < 12 ) %>%
filter(!is.na(LinkRatio)) %>%
mutate(Age1 = as.character(Age)) %>%
ggplot(aes(x = LinkRatio)) +
#geom_histogram() +
geom_density() +
facet_wrap(~Age, scale = 'free')
cum_dfs_cutoff %>% ungroup %>%
filter(is.na(ClsDate) | ClsDate == TransDate) %>%
filter(Age %% 6 == 0 | Age < 12 ) %>%
filter(!is.na(LinkRatio)) %>%
mutate(Age1 = as.character(Age)) %>%
filter(Segment = "Seg1") %>%
ggplot(aes(x = LinkRatio)) +
#geom_histogram() +
geom_density() +
facet_wrap(~Age, scale = 'free')
cum_dfs_cutoff %>% ungroup %>%
filter(is.na(ClsDate) | ClsDate == TransDate) %>%
filter(Age %% 6 == 0 | Age < 12 ) %>%
filter(!is.na(LinkRatio)) %>%
mutate(Age1 = as.character(Age)) %>%
filter(Segment == "Seg1") %>%
ggplot(aes(x = LinkRatio)) +
#geom_histogram() +
geom_density() +
facet_wrap(~Age, scale = 'free')
sim_gamma  <- function(k, theta, N = 5000) {
data.frame(x = rgamma(N, shape = k, scale = theta),
k = k)
}
sim_gamma(1, 1)
library(dplyr)
k <- seq(1, 10, 0.5)
theta <- 1 / k
sim_gamma  <- function(k, theta, N = 5000) {
data.frame(x = rgamma(N, shape = k, scale = theta),
k = k)
}
df <- bind_rows(mapply(sim_gamma, k = k, theta = theta))
df <- bind_rows(mapply(sim_gamma, k = k, theta = theta, SIMPLIFY = F))
library(ggplot2)
df %>%
ggplot(aes(x = x)) +
geom_density() +
facet_wrap(~k)
df %>%
ggplot(aes(x = x)) +
geom_density() +
facet_wrap(~k, scale = 'free')
library(tidyverse)
library(reshape2)
library(readr)
setwd("~/GitHub/new package play codes/Modeling/kaggle")
train_df <- read_csv("train.csv")
test_df <- read_csv("test.csv")
setwd("~/GitHub/new package play codes/Modeling/kaggle")
View(train_df)
setwd("~/GitHub/new package play codes/Modeling/kaggle/imbalanced classification example")
install.packages("ROSE")
library(ROSE)
data(hacide)
str(hacide.train)
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
install.packages("rpart")
library(rpart)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
View(pred.treeimb)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
#over sampling
data_balanced_over <- ovun.sample(cls ~ ., data = hacide.train, method = "over",N = 1960)$data
View(data_balanced_over)
#under sampling
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under", N = 40, seed = 1)$data
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both", p=0.5,
N=1000, seed = 1)$data
####sythetic
data.rose <- ROSE(cls ~ ., data = hacide.train, seed = 1)$data
#build decision tree models
tree.rose <- rpart(cls ~ ., data = data.rose)
tree.over <- rpart(cls ~ ., data = data_balanced_over)
tree.under <- rpart(cls ~ ., data = data_balanced_under)
tree.both <- rpart(cls ~ ., data = data_balanced_both)
#make predictions on unseen data
pred.tree.rose <- predict(tree.rose, newdata = hacide.test)
pred.tree.over <- predict(tree.over, newdata = hacide.test)
pred.tree.under <- predict(tree.under, newdata = hacide.test)
pred.tree.both <- predict(tree.both, newdata = hacide.test)
#AUC ROSE
roc.curve(hacide.test$cls, pred.tree.rose[,2])
#AUC Oversampling
roc.curve(hacide.test$cls, pred.tree.over[,2])
#AUC Undersampling
roc.curve(hacide.test$cls, pred.tree.under[,2])
#AUC Both
roc.curve(hacide.test$cls, pred.tree.both[,2])
ROSE.holdout <- ROSE.eval(cls ~ ., data = hacide.train,
learner = rpart, method.assess = "holdout",
extr.pred = function(obj)obj[,2], seed = 1)
(ROSE.holdout <- ROSE.eval(cls ~ ., data = hacide.train,
learner = rpart, method.assess = "holdout",
extr.pred = function(obj)obj[,2], seed = 1))
(ROSE.holdout <- ROSE.eval(cls ~ ., data = hacide.train,
learner = rpart, method.assess = "holdout",
extr.pred = function(obj)obj[,2], seed = 1))
(ROSE.boot <- ROSE.eval(cls ~ ., data = hacide.train,
learner = rpart, method.assess = "boott",
extr.pred = function(obj)obj[,2], seed = 1))
(ROSE.BOOT <- ROSE.eval(cls ~ ., data = hacide.train,
learner = rpart, method.assess = "BOOT",
extr.pred = function(obj)obj[,2], seed = 1))
install.packages("DMwR")
install.packages("DMwR")
install.packages("caret")
library(caret)
install.packages("pROC")
library(pROC)
library(tidyverse)
hyper <-read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/hypothyroid.data', header=F)
names <- read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/hypothyroid.names', header=F, sep='\t')[[1]]
names <- gsub(pattern =":|[.]",x = names, replacement="")
colnames(hyper) <- names
library(DMwR)
library(caret)
library(pROC)
library(tidyverse)
hyper <-read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/hypothyroid.data', header=F)
names <- read.csv('http://archive.ics.uci.edu/ml/machine-learning-databases/thyroid-disease/hypothyroid.names', header=F, sep='\t')[[1]]
names <- gsub(pattern =":|[.]",x = names, replacement="")
colnames(hyper) <- names
View(hyper)
table(hyper$`hypothyroid, negative`)
colnames(hyper) <-c("target", "age", "sex", "on_thyroxine", "query_on_thyroxine",
"on_antithyroid_medication", "thyroid_surgery", "query_hypothyroid",
"query_hyperthyroid", "pregnant", "sick", "tumor", "lithium",
"goitre", "TSH_measured", "TSH", "T3_measured", "T3", "TT4_measured",
"TT4", "T4U_measured", "T4U", "FTI_measured", "FTI", "TBG_measured",
"TBG")
hyper$target <- ifelse(hyper$target=='negative',0,1)
prop.table(table(hyper$target))
head(hyper,2)
install.packages("dplyr")
library(dplyr)
ind <- sapply(hyper, is.factor)
hyper[ind] <- lapply(hyper[ind], as.character)
hyper[ hyper == "?" ] = NA
hyper[ hyper == "f" ] = 0
hyper[ hyper == "t" ] = 1
hyper[ hyper == "n" ] = 0
hyper[ hyper == "y" ] = 1
hyper[ hyper == "M" ] = 0
hyper[ hyper == "F" ] = 1
hyper[ind] <- lapply(hyper[ind], as.numeric)
repalceNAsWithMean <- function(x) {replace(x, is.na(x), mean(x[!is.na(x)]))}
hyper <- repalceNAsWithMean(hyper)
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(hyper$target, p = .50,
list = FALSE,
times = 1)
trainSplit <- hyper[ splitIndex,]
testSplit <- hyper[-splitIndex,]
prop.table(table(trainSplit$target))
set.seed(1234)
splitIndex <- createDataPartition(hyper$target, p = .50,
list = FALSE,
times = 1)
trainSplit <- hyper[ splitIndex,]
testSplit <- hyper[-splitIndex,]
prop.table(table(trainSplit$target))
ctrl <- trainControl(method = "cv", number = 5)
tbmodel <- train(target ~ ., data = trainSplit, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred <- predict(tbmodel$finalModel, testSplit[,predictors])
library(pROC)
auc <- roc(testSplit$target, pred)
print(auc)
auc <- roc(testSplit$target, pred)
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
library(DMwR)
trainSplit$target <- as.factor(trainSplit$target)
trainSplit <- SMOTE(target ~ ., trainSplit, perc.over = 100, perc.under=200)
trainSplit$target <- as.numeric(trainSplit$target)
prop.table(table(trainSplit$target))
tbmodel <- train(target ~ ., data = trainSplit, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred <- predict(tbmodel$finalModel, testSplit[,predictors])
auc <- roc(testSplit$target, pred)
print(auc)
set.seed(1234)
splitIndex <- createDataPartition(hyper$target, p = .50,
list = FALSE,
times = 1)
trainSplit <- hyper[ splitIndex,]
testSplit <- hyper[-splitIndex,]
trainSplit$target <- as.factor(trainSplit$target)
trainSplit <- SMOTE(target ~ ., trainSplit, perc.over = 100, perc.under=200)
trainSplit$target <- as.numeric(trainSplit$target)
tbmodel <- train(target ~ ., data = trainSplit, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred <- predict(tbmodel$finalModel, testSplit[,predictors])
auc <- roc(testSplit$target, pred)
print(auc)
set.seed(1234)
splitIndex <- createDataPartition(hyper$target, p = .50,
list = FALSE,
times = 1)
trainSplit <- hyper[ splitIndex,]
testSplit <- hyper[-splitIndex,]
trainSplit$target <- as.factor(trainSplit$target)
trainSplit_SMOTE <- SMOTE(target ~ ., trainSplit, perc.over = 100, perc.under=200)
trainSplit_SMOTE <- trainSplit_SMOTE %>%
mutate(target = as.factor(target))
tbmodel_SMOTE <- train(target ~ ., data = trainSplit, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred_SMOTE  <- predict(tbmodel_SMOTE $finalModel, testSplit[,predictors])
auc_SMOTE  <- roc(testSplit$target, pred_SMOTE )
print(auc_SMOTE )
pred_SMOTE  <- predict(tbmodel_SMOTE$finalModel, testSplit[,predictors])
auc_SMOTE  <- roc(testSplit$target, pred_SMOTE )
print(auc_SMOTE )
tbmodel_SMOTE
pred_SMOTE
trainSplit_SMOTE <- SMOTE(target ~ ., trainSplit, perc.over = 100, perc.under=200)
trainSplit_SMOTE <- trainSplit_SMOTE %>%
mutate(target = as.numeric(target))
prop.table(table(trainSplit_SMOTE$target))
tbmodel_SMOTE <- train(target ~ ., data = trainSplit, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred_SMOTE  <- predict(tbmodel_SMOTE$finalModel, testSplit[,predictors])
auc_SMOTE  <- roc(testSplit$target, pred_SMOTE )
print(auc_SMOTE )
pred_SMOTE
trainSplit_SMOTE <- SMOTE(target ~ ., trainSplit, perc.over = 100, perc.under=200)
trainSplit_SMOTE <- trainSplit_SMOTE %>%
mutate(target = as.numeric(target))
prop.table(table(trainSplit_SMOTE$target))
tbmodel_SMOTE <- train(target ~ ., data = tbmodel_SMOTE, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred_SMOTE  <- predict(tbmodel_SMOTE$finalModel, testSplit[,predictors])
auc_SMOTE  <- roc(testSplit$target, pred_SMOTE )
print(auc_SMOTE )
trainSplit$target <- as.factor(trainSplit$target)
trainSplit_SMOTE <- SMOTE(target ~ ., trainSplit, perc.over = 100, perc.under=200)
trainSplit_SMOTE <- trainSplit_SMOTE %>%
mutate(target = as.numeric(target))
prop.table(table(trainSplit_SMOTE$target))
tbmodel_SMOTE <- train(target ~ ., data = trainSplit_SMOTE, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred_SMOTE  <- predict(tbmodel_SMOTE$finalModel, testSplit[,predictors])
auc_SMOTE  <- roc(testSplit$target, pred_SMOTE )
print(auc_SMOTE )
set.seed(1234)
splitIndex <- createDataPartition(hyper$target, p = .50,
list = FALSE,
times = 1)
trainSplit <- hyper[ splitIndex,]
testSplit <- hyper[-splitIndex,]
trainSplit$target <- as.factor(trainSplit$target)
trainSplit_SMOTE <- SMOTE(target ~ ., trainSplit, perc.over = 100, perc.under=200)
trainSplit_SMOTE <- trainSplit_SMOTE %>%
mutate(target = as.numeric(target))
prop.table(table(trainSplit_SMOTE$target))
tbmodel_SMOTE <- train(target ~ ., data = trainSplit_SMOTE, method = "treebag",
trControl = ctrl)
predictors <- names(trainSplit)[names(trainSplit) != 'target']
pred_SMOTE  <- predict(tbmodel_SMOTE$finalModel, testSplit[,predictors])
auc_SMOTE  <- roc(testSplit$target, pred_SMOTE )
print(auc_SMOTE )
library(DMwR)
library(DMwR)
library(caret)
setwd("~/GitHub/new package play codes/Modeling/kaggle/imbalanced classification example")
library(ROSE)
data(hacide)
str(hacide.train)
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
library(rpart)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
#over sampling
data_balanced_over <- ovun.sample(cls ~ ., data = hacide.train, method = "over",N = 1960)$data
#under sampling
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under", N = 40, seed = 1)$data
###both
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both", p=0.5,
N=1000, seed = 1)$data
####sythetic
data.rose <- ROSE(cls ~ ., data = hacide.train, seed = 1)$data
unique(hacide.train)
unique(hacide.train[[1]])
ROSE(cls ~ ., data = hacide.train, seed = 1)
?SMOTE
setwd("~/GitHub/new package play codes/Modeling/kaggle/imbalanced classification example")
library(ROSE)
data(hacide)
str(hacide.train)
table(hacide.train$cls)
prop.table(table(hacide.train$cls))
library(rpart)
treeimb <- rpart(cls ~ ., data = hacide.train)
pred.treeimb <- predict(treeimb, newdata = hacide.test)
accuracy.meas(hacide.test$cls, pred.treeimb[,2])
roc.curve(hacide.test$cls, pred.treeimb[,2], plotit = F)
#over sampling
data_balanced_over <- ovun.sample(cls ~ ., data = hacide.train, method = "over",N = 1960)$data
#under sampling
data_balanced_under <- ovun.sample(cls ~ ., data = hacide.train, method = "under", N = 40, seed = 1)$data
###both
data_balanced_both <- ovun.sample(cls ~ ., data = hacide.train, method = "both", p=0.5,
N=1000, seed = 1)$data
####sythetic
data.rose <- ROSE(cls ~ ., data = hacide.train, seed = 1)$data
trainSplit_SMOTE <- SMOTE(target ~ ., trainSplit, perc.over = 500, perc.under=200)
trainSplit_SMOTE <- SMOTE(target ~ ., hacide.train, perc.over = 500, perc.under=200)
trainSplit_SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 500, perc.under=200)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 500, perc.under=200)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 500, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 200, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 100, perc.under=200)
prop.table(table(train.SMOTE$cls))
tabl(hacide.train$cls)
table(hacide.train$cls)
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 600, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 600, perc.under=0)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 600, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 1000, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 1000, perc.under=80)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 1000, perc.under=90)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 1000, perc.under=95)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 2000, perc.under=95)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 2200, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 2500, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 2600, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 2700, perc.under=100)
prop.table(table(train.SMOTE$cls))
train.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 2500, perc.under=100)
prop.table(table(train.SMOTE$cls))
tree.rose <- rpart(cls ~ ., data = data.rose)
tree.over <- rpart(cls ~ ., data = data_balanced_over)
tree.under <- rpart(cls ~ ., data = data_balanced_under)
tree.both <- rpart(cls ~ ., data = data_balanced_both)
tree.SMOTE <- rpart(cls ~., data = data.SMOTE)
data.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 2500, perc.under=100)
prop.table(table(train.SMOTE$cls))
tree.rose <- rpart(cls ~ ., data = data.rose)
tree.over <- rpart(cls ~ ., data = data_balanced_over)
tree.under <- rpart(cls ~ ., data = data_balanced_under)
tree.both <- rpart(cls ~ ., data = data_balanced_both)
tree.SMOTE <- rpart(cls ~., data = data.SMOTE)
pred.tree.rose <- predict(tree.rose, newdata = hacide.test)
pred.tree.over <- predict(tree.over, newdata = hacide.test)
pred.tree.under <- predict(tree.under, newdata = hacide.test)
pred.tree.both <- predict(tree.both, newdata = hacide.test)
pred.tree.SMOTE <- predict(tree.SMOTE, newdata = hacide.test)
#AUC ROSE
roc.curve(hacide.test$cls, pred.tree.rose[,2])
#AUC Oversampling
roc.curve(hacide.test$cls, pred.tree.over[,2])
#AUC Undersampling
roc.curve(hacide.test$cls, pred.tree.under[,2])
#AUC Both
roc.curve(hacide.test$cls, pred.tree.both[,2])
#AUC SMOTE
roc.curve(hacide.test$cls, pred.tree.SMOTE[,2])
data.SMOTE <- SMOTE(cls ~ ., hacide.train, perc.over = 200, perc.under=100)
prop.table(table(train.SMOTE$cls))
#build decision tree models
tree.rose <- rpart(cls ~ ., data = data.rose)
tree.over <- rpart(cls ~ ., data = data_balanced_over)
tree.under <- rpart(cls ~ ., data = data_balanced_under)
tree.both <- rpart(cls ~ ., data = data_balanced_both)
tree.SMOTE <- rpart(cls ~., data = data.SMOTE)
#make predictions on unseen data
pred.tree.rose <- predict(tree.rose, newdata = hacide.test)
pred.tree.over <- predict(tree.over, newdata = hacide.test)
pred.tree.under <- predict(tree.under, newdata = hacide.test)
pred.tree.both <- predict(tree.both, newdata = hacide.test)
pred.tree.SMOTE <- predict(tree.SMOTE, newdata = hacide.test)
#AUC ROSE
roc.curve(hacide.test$cls, pred.tree.rose[,2])
#AUC Oversampling
roc.curve(hacide.test$cls, pred.tree.over[,2])
#AUC Undersampling
roc.curve(hacide.test$cls, pred.tree.under[,2])
#AUC Both
roc.curve(hacide.test$cls, pred.tree.both[,2])
#AUC SMOTE
roc.curve(hacide.test$cls, pred.tree.SMOTE[,2])
(ROSE.holdout <- ROSE.eval(cls ~ ., data = hacide.train,
learner = rpart, method.assess = "holdout",
extr.pred = function(obj)obj[,2], seed = 1))
(ROSE.BOOT <- ROSE.eval(cls ~ ., data = hacide.train,
learner = rpart, method.assess = "BOOT",
extr.pred = function(obj)obj[,2], seed = 1))
library(tidyverse)
library(reshape2)
library(readr)
library(naniar)
setwd("~/GitHub/new package play codes/Modeling/kaggle")
train_df <- read_csv("train.csv")
test_df <- read_csv("test.csv")
library(ROSE)
library(DMwR)
str(train_df)
train_df1 <- train_df %>% select(-id)
rm(train_df1)
data.rose <- ROSE(target ~ ., data = train_df1 %>% select(-id), seed = 12345)$data
data.rose <- ROSE(target ~ ., data = train_df %>% select(-id), seed = 12345)$data
data.SMOTE <- SMOTE(target ~ ., train_df %>% select(-id), perc.over = 100, perc.under=200)
?SMOTE
data.SMOTE <- SMOTE(target ~ ., data = train_df %>% select(-id), perc.over = 100, perc.under=200)
data.SMOTE <- SMOTE(target ~ ., data = train_df %>% select(-id) %>% as.data.frame,
perc.over = 100, perc.under=200)
data.SMOTE <- SMOTE(target ~ ., data = train_df %>% select(-id) %>% as.data.frame(),
perc.over = 100, perc.under=200)
str(train_df)
train_df <- train_df %>% mutate(target = as.factor(target))
test_df <- test_df %>% mutate(target = as.factor(target))
data.rose <- ROSE(target ~ ., data = train_df %>% select(-id), seed = 12345)$data
data.SMOTE <- SMOTE(target ~ ., data = train_df %>% select(-id) %>% as.data.frame(),
perc.over = 100, perc.under=200)
library(tidyverse)
library(reshape2)
library(readr)
library(ROSE)
library(DMwR)
library(caret)
setwd("~/GitHub/new package play codes/Modeling/kaggle")
train_df <- read_csv("train.7z")
test_df <- read_csv("test.7z")
train_df <- read_csv("train.zip")
test_df <- read_csv("test.zip")
train_df <- train_df %>% mutate(target = as.factor(target))
set.seed(1234)
splitIndex <- createDataPartition(train_df$target, p = .50,
list = FALSE,
times = 1)
train_df1  <- train_df[ splitIndex,]
valid_df <- train_df[-splitIndex,]
train_df1 %>% filter(target == 1) %>% nrow()
system.time(data.rose <- ROSE(target ~ ., data = train_df1 %>% select(-id), seed = 12345)$data)
system.time(data.under <- ovun.sample(target ~ ., data = train_df1 %>% select(-id), method = "under",
N = 2 * train_df1 %>% filter(target == 1) %>% nrow(), seed = 1)$data)
system.time(tree.rose <- rpart(target ~ ., data = data.rose))
system.time(tree.under <- rpart(target ~ ., data = data.under))
?ROSE
system.time(data.rose1 <- ROSE(target ~ ., data = train_df1 %>% select(-id), N = 50000,  seed = 12345)$data)
system.time(tree.rose1 <- rpart(target ~ ., data = data.rose1))
system.time(pred.tree.rose <- predict(tree.rose, newdata = valid_df))
system.time(pred.tree.under <- predict(tree.under, newdata = valid_df))
system.time(pred.tree.rose1 <- predict(tree.rose1, newdata = valid_df))
roc.curve(valid_df$target, pred.tree.rose[,2])
#AUC ROSE1
roc.curve(valid_df$target, pred.tree.rose1[,2])
#AUC Undersampling
roc.curve(valid_df$target, pred.tree.under[,2])
summary(data.rose1)
